import os
import sys
import gradio as gr
import pillow_heif
import torch
import devicetorch
import subprocess
import gc
import psutil  # for system stats - gpu/cpu etc
import random
import shutil

from PIL import Image
from typing import List
from pathlib import Path
from datetime import datetime
from gradio_imageslider import ImageSlider
from huggingface_hub import hf_hub_download
from transformers import AutoModelForCausalLM, AutoProcessor

from refiners.fluxion.utils import manual_seed
from refiners.foundationals.latent_diffusion import Solver, solvers
from enhancer import ESRGANUpscaler, ESRGANUpscalerCheckpoints
from system_monitor import SystemMonitor
from message_manager import MessageManager

import warnings
# Filter out the timm deprecation warning
warnings.filterwarnings("ignore", category=FutureWarning, module="timm.models.layers")
# Filter the GenerationMixin inheritance warning
warnings.filterwarnings("ignore", message=".*has generative capabilities.*")
# Filter the PyTorch flash attention warning
warnings.filterwarnings("ignore", message=".*Torch was not compiled with flash attention.*")

pillow_heif.register_heif_opener()
pillow_heif.register_avif_opener()

message_manager = MessageManager()

last_seed = None
save_path = "../outputs"   # Can be changed to a preferred directory: "C:\path\to\save_folder"
os.makedirs(save_path, exist_ok=True)
MAX_GALLERY_IMAGES = 30
VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.webp', '.heic', '.heif', '.avif'}


CHECKPOINTS = ESRGANUpscalerCheckpoints(
    unet=Path(
        hf_hub_download(
            repo_id="refiners/juggernaut.reborn.sd1_5.unet",
            filename="model.safetensors",
            revision="347d14c3c782c4959cc4d1bb1e336d19f7dda4d2",
        )
    ),
    clip_text_encoder=Path(
        hf_hub_download(
            repo_id="refiners/juggernaut.reborn.sd1_5.text_encoder",
            filename="model.safetensors",
            revision="744ad6a5c0437ec02ad826df9f6ede102bb27481",
        )
    ),
    lda=Path(
        hf_hub_download(
            repo_id="refiners/juggernaut.reborn.sd1_5.autoencoder",
            filename="model.safetensors",
            revision="3c1aae3fc3e03e4a2b7e0fa42b62ebb64f1a4c19",
        )
    ),
    controlnet_tile=Path(
        hf_hub_download(
            repo_id="refiners/controlnet.sd1_5.tile",
            filename="model.safetensors",
            revision="48ced6ff8bfa873a8976fa467c3629a240643387",
        )
    ),
    esrgan=Path(
        hf_hub_download(
            repo_id="philz1337x/upscaler",
            filename="4x-UltraSharp.pth",
            revision="011deacac8270114eb7d2eeff4fe6fa9a837be70",
        )
    ),
    negative_embedding=Path(
        hf_hub_download(
            repo_id="philz1337x/embeddings",
            filename="JuggernautNegative-neg.pt",
            revision="203caa7e9cc2bc225031a4021f6ab1ded283454a",
        )
    ),
    negative_embedding_key="string_to_param.*",
    
    loras={
        "more_details": Path(
            hf_hub_download(
                repo_id="philz1337x/loras",
                filename="more_details.safetensors",
                revision="a3802c0280c0d00c2ab18d37454a8744c44e474e",
            )
        ),
        "sdxl_render": Path(
            hf_hub_download(
                repo_id="philz1337x/loras",
                filename="SDXLrender_v2.0.safetensors",
                revision="a3802c0280c0d00c2ab18d37454a8744c44e474e",
            )
        ),
    },
)

device = torch.device(devicetorch.get(torch))
dtype = devicetorch.dtype(torch, "bfloat16")
enhancer = ESRGANUpscaler(checkpoints=CHECKPOINTS, device=device, dtype=dtype)


def generate_prompt(image: Image.Image, caption_detail: str = "<CAPTION>") -> str:
    """
    ä½¿ç”¨ Florence-2 ä¸ºå›¾ç‰‡ç”Ÿæˆè¯¦ç»†æè¿°ã€‚
    """
    if image is None:
        message_manager.add_warning("è¯·å…ˆåŠ è½½å›¾ç‰‡!")
        return gr.Warning("è¯·å…ˆåŠ è½½å›¾ç‰‡!")
        
    try:
        message_manager.add_message(f"å¼€å§‹ä½¿ç”¨ Florence-2 ç”Ÿæˆæè¿°ï¼Œè¯¦ç»†ç¨‹åº¦: {caption_detail}")
        device = torch.device(devicetorch.get(torch))
        torch_dtype = devicetorch.dtype(torch, "bfloat16")
        
        gc.collect()
        devicetorch.empty_cache(torch)
        message_manager.add_message("æ­£åœ¨åŠ è½½ Florence-2 æ¨¡å‹...")

        # Load model in eval mode immediately
        model = AutoModelForCausalLM.from_pretrained(
            "multimodalart/Florence-2-large-no-flash-attn", 
            torch_dtype=torch_dtype,
            trust_remote_code=True
        ).eval()
        
        processor = AutoProcessor.from_pretrained(
            "multimodalart/Florence-2-large-no-flash-attn",
            trust_remote_code=True
        )
        message_manager.add_success("Florence-2 æ¨¡å‹åŠ è½½æˆåŠŸ")

        # Move model to device after eval mode
        model = devicetorch.to(torch, model)
        message_manager.add_message("æ­£åœ¨ä½¿ç”¨ Florence-2 å¤„ç†å›¾ç‰‡...")

        # Process the image
        inputs = processor(
            text=caption_detail, 
            images=image.convert("RGB"), 
            return_tensors="pt"
        )
        
        # Convert inputs to the correct dtype and move to device
        inputs = {
            k: v.to(device=device, dtype=torch_dtype if v.dtype == torch.float32 else v.dtype) 
            for k, v in inputs.items()
        }

        # Generate caption with no grad
        with torch.no_grad():
            generated_ids = model.generate(
                input_ids=inputs["input_ids"],
                pixel_values=inputs["pixel_values"],
                max_new_tokens=512,
                num_beams=2
            )
            
            # Move generated_ids to CPU immediately
            generated_ids = generated_ids.cpu()

        # Clear inputs from GPU
        inputs = {k: v.cpu() for k, v in inputs.items()}
        devicetorch.empty_cache(torch)
        
        # Process the generated text
        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]
        parsed_answer = processor.post_process_generation(
            generated_text,
            task=caption_detail,
            image_size=(image.width, image.height)
        )
        
        # Clean up the caption and add enhancement-specific terms
        raw_caption = parsed_answer[caption_detail]
        caption_text = clean_caption(raw_caption)
        enhanced_prompt = f"masterpiece, best quality, highres, {caption_text}"
        
        message_manager.add_message("åŸå§‹æè¿°: " + raw_caption)
        message_manager.add_success(f"ç”Ÿæˆçš„æç¤ºè¯: {enhanced_prompt}")

        # Aggressive cleanup
        del generated_ids
        del inputs
        model.cpu()
        del model
        del processor
        gc.collect()
        devicetorch.empty_cache(torch)
        message_manager.add_message("æ¸…ç† Florence-2 èµ„æº")
            
        return enhanced_prompt
        
    except Exception as e:
        # Ensure cleanup happens even on error
        gc.collect()
        devicetorch.empty_cache(torch)
        message_manager.add_error(f"ç”Ÿæˆæè¿°æ—¶å‡ºé”™: {str(e)}")
        return gr.Warning(f"Error generating prompt: {str(e)}")
        
        
def clean_caption(text: str) -> str:
    """
    é€šè¿‡åˆ é™¤å¸¸è§å‰ç¼€ã€å¡«å……çŸ­è¯­å’Œæ‚¬ç©ºæè¿°æ¥æ¸…ç†æè¿°æ–‡æœ¬ã€‚
    """
    # è¦åˆ é™¤çš„å¸¸è§å‰ç¼€
    replacements = [
        "å›¾ç‰‡æ˜¾ç¤º ",
        "å›¾ç‰‡æ˜¯ ",
        "å›¾ç‰‡æç»˜ ",
        "è¿™å¼ å›¾ç‰‡æ˜¾ç¤º ",
        "è¿™å¼ å›¾ç‰‡æç»˜ ",
        "ç…§ç‰‡æ˜¾ç¤º ",
        "ç…§ç‰‡æç»˜ ",
        "å›¾æ˜¾ç¤º ",
        "å›¾åƒæç»˜ ",
        "æ•´ä½“æ°›å›´ ",
        "å›¾ç‰‡çš„æ°›å›´ ",
        "æœ‰ä¸€ä¸ª ",
        "æˆ‘ä»¬å¯ä»¥çœ‹åˆ° ",
    ]
    
    cleaned_text = text
    for phrase in replacements:
        cleaned_text = cleaned_text.replace(phrase, "")
    
    # åˆ é™¤æƒ…ç»ª/æ°›å›´ç›¸å…³ç‰‡æ®µ
    mood_patterns = [
        ". æ°›å›´æ˜¯ ",
        ". æ°”æ°›æ˜¯ ",
        ". å›¾ç‰‡çš„æ„Ÿè§‰æ˜¯ ",
        ". æ•´ä½“æ„Ÿè§‰æ˜¯ ",
        ". åŸºè°ƒæ˜¯ ",
    ]
    
    for pattern in mood_patterns:
        if pattern in cleaned_text:
            cleaned_text = cleaned_text.split(pattern)[0]
    
    # åˆ é™¤å°¾éƒ¨ç‰‡æ®µ
    while cleaned_text.endswith((" æ˜¯", " æœ‰", " å’Œ", " ä¸", " çš„")):
        cleaned_text = cleaned_text.rsplit(" ", 1)[0]
    
    return cleaned_text.strip()


def get_seed(seed_value: int, reuse: bool) -> int:
    """å¤„ç†ç§å­ç”Ÿæˆå’Œé‡ç”¨é€»è¾‘ã€‚"""
    global last_seed
    
    if reuse and last_seed is not None:
        return last_seed
    
    if seed_value == -1:
        generated_seed = random.randint(0, 10_000)
        last_seed = generated_seed
        return generated_seed
    
    last_seed = seed_value
    return seed_value

    
def process(
    input_image: Image.Image,
    prompt: str = "",
    negative_prompt: str = "",
    seed: int = -1,
    reuse_seed: bool = False,
    upscale_factor: int = 2,
    controlnet_scale: float = 0.6,
    controlnet_decay: float = 1.0,
    condition_scale: int = 6,
    tile_width: int = 112,
    tile_height: int = 144,
    denoise_strength: float = 0.35,
    num_inference_steps: int = 18,
    solver: str = "DDIM",
    auto_save_enabled: bool = True,  
) -> tuple[Image.Image, Image.Image]:
    try:
        # è¾“å…¥éªŒè¯
        if input_image is None:
            message_manager.add_warning("è¯·å…ˆåŠ è½½å›¾ç‰‡!")
            return gr.Warning("è¯·å…ˆåŠ è½½å›¾ç‰‡!")
            
        actual_seed = get_seed(seed, reuse_seed)
        message_manager.add_message(f"å¼€å§‹å¢å¼ºï¼Œä½¿ç”¨ç§å­å€¼ {actual_seed}")
        message_manager.add_message(f"æ”¾å¤§å€æ•°: {upscale_factor}x")
        
        # å¤„ç†å‰æ¸…ç†å†…å­˜
        gc.collect()
        devicetorch.empty_cache(torch)
        
        manual_seed(actual_seed)
        solver_type: type[Solver] = getattr(solvers, solver)

        # ä½¿ç”¨ no_grad ä¸Šä¸‹æ–‡
        with torch.no_grad():
            message_manager.add_message("æ­£åœ¨å¤„ç†å›¾ç‰‡...")
            enhanced_image = enhancer.upscale(
                image=input_image,
                prompt=prompt,
                negative_prompt=negative_prompt,
                upscale_factor=upscale_factor,
                controlnet_scale=controlnet_scale,
                controlnet_scale_decay=controlnet_decay,
                condition_scale=condition_scale,
                tile_size=(tile_height, tile_width),
                denoise_strength=denoise_strength,
                num_inference_steps=num_inference_steps,
                loras_scale={"more_details": 0.5, "sdxl_render": 1.0},
                solver_type=solver_type,
            )

        global latest_result
        latest_result = enhanced_image
        message_manager.add_success("å¢å¼ºå®Œæˆ!")
        
        if auto_save_enabled:
            save_output(enhanced_image, True)
        
        # å¤„ç†åæ¸…ç†å†…å­˜
        gc.collect()
        devicetorch.empty_cache(torch)
        message_manager.add_message("å·²æ¸…ç†èµ„æº")
        
        return (input_image, enhanced_image)
        
    except Exception as e:
        message_manager.add_error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        gc.collect()
        devicetorch.empty_cache(torch)
        return gr.Warning(f"Error during processing: {str(e)}")

        
def batch_process_images(
    files,
    prompt: str = "",
    negative_prompt: str = "",
    seed: int = -1,
    reuse_seed: bool = False,
    upscale_factor: int = 2,
    controlnet_scale: float = 0.6,
    controlnet_decay: float = 1.0,
    condition_scale: int = 6,
    tile_width: int = 112,
    tile_height: int = 144,
    denoise_strength: float = 0.35,
    num_inference_steps: int = 18,
    solver: str = "DDIM",
    progress=gr.Progress()
) -> tuple[str, List[str], tuple[Image.Image, Image.Image]]:
    """
    ä½¿ç”¨å¢å¼ºå™¨å¤„ç†å¤šä¸ªå›¾ç‰‡å¹¶ç›´æ¥ä¿å­˜åˆ°æ‰¹å¤„ç†å­æ–‡ä»¶å¤¹ã€‚
    """
    def generate_summary():
        """ç”Ÿæˆæ‰¹å¤„ç†æ‘˜è¦çš„è¾…åŠ©å‡½æ•°"""
        summary = [
            f"å¤„ç†å®Œæˆ!",
            f"æˆåŠŸå¤„ç†: {results['successful']} å¼ å›¾ç‰‡",
            f"å¤±è´¥: {results['failed']} å¼ å›¾ç‰‡",
            f"è·³è¿‡: {results['skipped']} å¼ å›¾ç‰‡",
            f"\nä¿å­˜åˆ°æ–‡ä»¶å¤¹: {batch_folder}"
        ]
        
        if results['error_files']:
            summary.append("\né”™è¯¯åˆ—è¡¨:")
            summary.extend(results['error_files'])
            
        return "\n".join(summary)

    if not files:
        message_manager.add_warning("æœªé€‰æ‹©è¦æ‰¹é‡å¤„ç†çš„æ–‡ä»¶")
        return "è¯·ä¸Šä¼ ä¸€äº›å›¾ç‰‡è¿›è¡Œå¤„ç†ã€‚", [], (None, None)
        
    results = {
        'successful': 0,
        'failed': 0,
        'skipped': 0,
        'processed_files': [],
        'error_files': []
    }
    
    valid_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.heic', '.heif', '.avif'}
    
    timestamp = datetime.now().strftime('%y%m%d_%H%M%S')
    batch_folder = os.path.join(save_path, f"batch_{timestamp}")
    os.makedirs(batch_folder, exist_ok=True)
    message_manager.add_message(f"åˆ›å»ºæ‰¹å¤„ç†æ–‡ä»¶å¤¹: {batch_folder}")
    
    current_image_pair = (None, None)
    
    try:
        total_files = len(files)
        message_manager.add_message(f"å¼€å§‹æ‰¹é‡å¤„ç† {total_files} ä¸ªæ–‡ä»¶")
        
        for i, file in enumerate(files, 1):
            try:
                # Update progress
                progress(i/total_files, f"Processing {i}/{total_files}")
                message_manager.add_message(f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{total_files} ä¸ªæ–‡ä»¶: {file.name}")
                
                # Check file extension
                file_ext = os.path.splitext(file.name)[1].lower()
                if file_ext not in valid_extensions:
                    message_manager.add_warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {file.name}")
                    results['skipped'] += 1
                    results['error_files'].append(f"{os.path.basename(file.name)} (ä¸æ”¯æŒçš„æ ¼å¼)")
                    
                    if i == total_files:
                        message_manager.add_success("æ‰¹é‡å¤„ç†å®Œæˆ")
                        yield generate_summary(), update_gallery(), current_image_pair
                    else:
                        yield (
                            f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{total_files} ä¸ªæ–‡ä»¶: {file.name}",
                            update_gallery(),
                            current_image_pair
                        )
                    continue
                
                # Load and process image
                input_image = Image.open(file.name).convert("RGB")
                
                # å¤„ç†å‰æ¸…ç†å†…å­˜
                gc.collect()
                devicetorch.empty_cache(torch)
                
                # Process with the same parameters as single image processing
                actual_seed = get_seed(seed, reuse_seed)
                manual_seed(actual_seed)
                solver_type: type[Solver] = getattr(solvers, solver)
                
                with torch.no_grad():
                    enhanced_image = enhancer.upscale(
                        image=input_image,
                        prompt=prompt,
                        negative_prompt=negative_prompt,
                        upscale_factor=upscale_factor,
                        controlnet_scale=controlnet_scale,
                        controlnet_scale_decay=controlnet_decay,
                        condition_scale=condition_scale,
                        tile_size=(tile_height, tile_width),
                        denoise_strength=denoise_strength,
                        num_inference_steps=num_inference_steps,
                        loras_scale={"more_details": 0.5, "sdxl_render": 1.0},
                        solver_type=solver_type,
                    )
                
                # Update the current image pair for the slider
                current_image_pair = (input_image, enhanced_image)
                
                # Save enhanced image to batch folder
                original_name = Path(file.name).stem
                enhanced_filename = f"{original_name}_enhanced.png"
                output_path = os.path.join(batch_folder, enhanced_filename)
                enhanced_image.save(output_path, "PNG")
                
                # Update results
                results['successful'] += 1
                results['processed_files'].append(enhanced_filename)
                message_manager.add_success(f"å·²ä¿å­˜: {enhanced_filename}")
                
                # For the last file, show the summary instead of progress
                if i == total_files:
                    message_manager.add_success("æ‰¹é‡å¤„ç†å®Œæˆ")
                    yield generate_summary(), update_gallery(), current_image_pair
                else:
                    yield (
                        f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{total_files} ä¸ªæ–‡ä»¶: {file.name}",
                        update_gallery(),
                        current_image_pair
                    )
                
                # å¤„ç†åæ¸…ç†å†…å­˜
                gc.collect()
                devicetorch.empty_cache(torch)
                
            except Exception as e:
                message_manager.add_error(f"Error processing {file.name}: {str(e)}")
                results['failed'] += 1
                results['error_files'].append(f"{os.path.basename(file.name)} ({str(e)})")
                
                if i == total_files:
                    message_manager.add_success("æ‰¹é‡å¤„ç†å®Œæˆ")
                    yield generate_summary(), update_gallery(), current_image_pair
        
        # Final return for gradio
        return generate_summary(), update_gallery(), current_image_pair
        
    except Exception as e:
        error_msg = f"æ‰¹é‡å¤„ç†é”™è¯¯: {str(e)}"
        message_manager.add_error(error_msg)
        return error_msg, [], (None, None)
            
            
def open_output_folder() -> None:
    folder_path = os.path.abspath(save_path)
    
    try:
        os.makedirs(folder_path, exist_ok=True)
    except Exception as e:
        message_manager.add_error(f"åˆ›å»ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return
        
    try:
        if os.name == 'nt':  # Windows
            subprocess.run(['explorer', folder_path])
        elif os.name == 'posix':  # macOS and Linux
            subprocess.run(['xdg-open' if os.name == 'posix' else 'open', folder_path])
        message_manager.add_success(f"å·²æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹: {folder_path}")
    except Exception as e:
        message_manager.add_error(f"æ‰“å¼€æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")


def save_output(image: Image.Image = None, auto_saved: bool = False) -> List[str]:
    """ä¿å­˜å›¾ç‰‡å¹¶è¿”å›æ›´æ–°åçš„å›¾åº“æ•°æ®"""
    if image is None:
        if not globals().get('latest_result'):
            message_manager.add_warning("æ²¡æœ‰å¯ä¿å­˜çš„å›¾ç‰‡! è¯·å…ˆå¢å¼ºå›¾ç‰‡ã€‚")
            return []
        image = latest_result
        
    try:
        # Create output directory if it doesn't exist
        os.makedirs(save_path, exist_ok=True)
        
        # Generate filename with timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"enhanced_{timestamp}.png"
        filepath = os.path.join(save_path, filename)
        
        # Save the image
        image.save(filepath, "PNG")
        
        save_type = "è‡ªåŠ¨ä¿å­˜" if auto_saved else "å·²ä¿å­˜"
        message = f"å›¾ç‰‡{save_type}ä¸º: {filename}"
        message_manager.add_success(message)
        
        # Return updated gallery data
        return update_gallery()
        
    except Exception as e:
        error_msg = f"ä¿å­˜å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}"
        message_manager.add_error(error_msg)
        return []
        
        
def process_and_update(*args):
    """å¤„ç†è¾“å‡ºå’Œå›¾åº“æ›´æ–°çš„åŒ…è£…å‡½æ•°"""
    result = process(*args)  # è·å–æ»‘å—å›¾ç‰‡
    return result, update_gallery()  # è·å–å½“å‰å›¾åº“çŠ¶æ€
    
    
def update_gallery() -> List[str]:
    """ä½¿ç”¨ä¿å­˜è·¯å¾„å’Œæ‰¹å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æœ€æ–°å›¾ç‰‡æ›´æ–°å›¾åº“ã€‚"""
    try:
        # ä»ä¸»ä¿å­˜è·¯å¾„å’Œæ‰¹å¤„ç†å­æ–‡ä»¶å¤¹è·å–æ‰€æœ‰å›¾ç‰‡
        batch_folders = [d for d in os.listdir(save_path) 
                        if os.path.isdir(os.path.join(save_path, d)) 
                        and d.startswith('batch_')]
        
        # æ”¶é›†ä¸»æ–‡ä»¶å¤¹å’Œæ‰€æœ‰æ‰¹å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
        all_images = []
        
        # ä¸»æ–‡ä»¶å¤¹å›¾ç‰‡
        main_images = [
            os.path.join(save_path, f) 
            for f in os.listdir(save_path) 
            if f.lower().endswith(tuple(VALID_EXTENSIONS))
        ]
        all_images.extend(main_images)
        
        # æ‰¹å¤„ç†æ–‡ä»¶å¤¹å›¾ç‰‡
        for batch_folder in batch_folders:
            folder_path = os.path.join(save_path, batch_folder)
            batch_images = [
                os.path.join(folder_path, f)
                for f in os.listdir(folder_path)
                if f.lower().endswith(tuple(VALID_EXTENSIONS))
            ]
            all_images.extend(batch_images)
        
        # æŒ‰æœ€æ–°ä¼˜å…ˆæ’åºå¹¶é™åˆ¶æ•°é‡
        all_images.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        return all_images[:MAX_GALLERY_IMAGES]
        
    except Exception as e:
        message_manager.add_error(f"æ›´æ–°å›¾åº“æ—¶å‡ºé”™: {str(e)}")
        return []


css = """
/* å›¾ç‰‡çš„å…·ä½“è°ƒæ•´ */
.image-container .image-custom {
    max-width: 100% !important;
    max-height: 80vh !important;
    width: auto !important;
    height: auto !important;
}

/* å±…ä¸­ ImageSlider å®¹å™¨å¹¶ä¿æŒæ»‘å—çš„å®Œæ•´å®½åº¦ */
.image-container .image-slider-custom {
    display: flex !important;
    justify-content: center !important;
    align-items: center !important;
    width: 100% !important;
}

/* æ»‘å—å®¹å™¨çš„æ ·å¼ */
.image-container .image-slider-custom > div {
    width: 100% !important;
    max-width: 100% !important;
    max-height: 80vh !important;
}

/* ç¡®ä¿å‰åå›¾ç‰‡ä¿æŒå®½é«˜æ¯” */
.image-container .image-slider-custom img {
    max-height: 80vh !important;
    width: 100% !important;
    height: auto !important;
    object-fit: contain !important;
}

/* æ»‘å—æ‰‹æŸ„çš„æ ·å¼ */
.image-container .image-slider-custom .image-slider-handle {
    width: 2px !important;
    background: white !important;
    border: 2px solid rgba(0, 0, 0, 0.6) !important;
}

/* æ§åˆ¶å°æ»šåŠ¨æ ·å¼ */
.console-scroll textarea {
    max-height: 12em !important;  /* Approximately 8 lines of text */
    overflow-y: auto !important;  /* Enables vertical scrolling */
}

/* çŠ¶æ€ç‰¹å®šæ ·å¼ */
.batch-status textarea {
    min-height: 12em !important;  /* Ensures minimum height for welcome message */
}

/* æç¤ºæŒ‡å—æ ·å¼ */
.prompt-guide textarea {
    white-space: pre-wrap !important;  /* Preserves formatting but allows wrapping */
    padding-left: 1em !important;      /* Base padding for all text */
    text-indent: -1em !important;      /* Negative indent for first line */
}

"""

# å­˜å‚¨æœ€æ–°çš„å¤„ç†ç»“æœ
latest_result = None

with gr.Blocks(css=css) as demo:
    with gr.Row():
        with gr.Column(elem_classes="image-container"):
            with gr.Tabs() as tabs:
                with gr.TabItem("å•å¼ å›¾ç‰‡") as single_tab:
                    input_image = gr.Image(type="pil", label="è¾“å…¥å›¾ç‰‡", elem_classes=["image-custom"])
                    run_button = gr.ClearButton(
                        components=None,
                        value="å¢å¼ºå›¾ç‰‡",
                        variant="primary"
                    )
                with gr.TabItem("æ‰¹é‡å¤„ç†") as batch_tab:
                    batch_welcome = """âœ¨ æ¬¢è¿ä½¿ç”¨æ‰¹é‡å¤„ç†! âœ¨

ğŸ“¸ æ‹–æ”¾å¤šä¸ªå›¾ç‰‡è¿›è¡Œæ‰¹é‡å¢å¼º:
    
â€¢ æ‰€æœ‰å¢å¼ºè®¾ç½®å°†åº”ç”¨äºæ¯å¼ å›¾ç‰‡
   (æç¤ºè¯ã€é™å™ªã€ç§å­ç­‰ - æ³¨æ„:ç§å­é»˜è®¤éšæœº)
â€¢ å›¾ç‰‡å°†ä¿å­˜åˆ°å¸¦æ—¶é—´æˆ³çš„æ‰¹å¤„ç†æ–‡ä»¶å¤¹
â€¢ å¢å¼ºæ•ˆæœä¼šåœ¨é¢„è§ˆçª—å£æ˜¾ç¤º
â€¢ åœ¨æ­¤å¤„è·Ÿè¸ªè¿›åº¦ + ä¸»æ§åˆ¶å°æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

ğŸš€ å‡†å¤‡å¥½äº†å—? æ‹–å…¥å›¾ç‰‡å¹¶ç‚¹å‡»'å¼€å§‹æ‰¹é‡å¤„ç†'!"""

                    input_files = gr.File(
                        file_count="multiple",
                        label="åŠ è½½å›¾ç‰‡",
                        scale=2
                    )
                    batch_status = gr.Textbox(
                        label="æ‰¹å¤„ç†çŠ¶æ€",
                        value=batch_welcome,
                        interactive=False,
                        show_copy_button=True,
                        autoscroll=True,
                        elem_classes="batch-status"
                    )
                    batch_button = gr.Button(
                        "å¼€å§‹æ‰¹é‡å¤„ç†",
                        variant="primary"
                    )
           
        with gr.Column(elem_classes="image-container"):
            output_slider = ImageSlider(
                interactive=False,
                label="å‰åå¯¹æ¯”",
                elem_classes=["image-slider-custom"]
            )
            run_button.add(output_slider)
            with gr.Row():
                save_result = gr.Button("ä¿å­˜ç»“æœ", scale=2)
                auto_save = gr.Checkbox(label="è‡ªåŠ¨ä¿å­˜", value=True)
                open_folder_button = gr.Button("æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹", scale=2)

    with gr.Accordion("æç¤ºè¯è®¾ç½®", open=False):
        with gr.Row():
            with gr.Tabs():
                with gr.TabItem("æç¤ºè¯"):
                    prompt = gr.Textbox(
                        label="å¢å¼ºæç¤ºè¯",
                        value="masterpiece, best quality, highres",
                        show_label=True
                    )
                with gr.TabItem("æŒ‡å—"):
                    prompt_guide = gr.Textbox(
    value="""ğŸ’¡ æç¤ºè¯æŒ‡å—

ğŸ¯ é™„åŠ æç¤ºè¯æ˜¯å¯é€‰çš„ï¼
â€¢ å®ƒä»¬çš„å·¥ä½œæ–¹å¼ç±»ä¼¼äºå…¶ä»–AIç”Ÿæˆåº”ç”¨ä¸­çš„img2imgå’Œcontrolnetæç¤ºè¯
â€¢ é»˜è®¤è®¾ç½®å¯¹ä¸€èˆ¬å¢å¼ºæ•ˆæœå¾ˆå¥½
â€¢ ä½¿ç”¨æç¤ºè¯æ¥å¼•å¯¼AIè¿›è¡Œç‰¹å®šçš„æ”¹è¿›
â€¢ ä¿æŒæç¤ºè¯ç®€å•å¹¶ä¸“æ³¨äºä½ æƒ³è¦å¢å¼ºçš„éƒ¨åˆ†

ğŸ“ ç¤ºä¾‹æç¤ºè¯:
â€¢ "sharp details, high quality" - æé«˜æ¸…æ™°åº¦å’Œç»†èŠ‚
â€¢ "vivid colors, high contrast" - è·å¾—æ›´ç”ŸåŠ¨çš„æ•ˆæœ
â€¢ "soft lighting, smooth details" - è·å¾—æ›´æŸ”å’Œçš„å¢å¼ºæ•ˆæœ
â€¢ "perfect eyes", "green eyes", "detailed fingernails" ç­‰ - å…³æ³¨ç‰¹å®šç»†èŠ‚

ğŸ’­ æç¤º:
â€¢ ä»é»˜è®¤æç¤ºè¯å¼€å§‹ï¼Œéœ€è¦æ—¶å†æ·»åŠ ç‰¹å®šå¼•å¯¼
â€¢ Florence2è‡ªåŠ¨æç¤ºæ˜¯å®Œå…¨å¯é€‰çš„ã€‚æ·»åŠ å®ƒä¸»è¦æ˜¯å› ä¸ºä¸ºä»€ä¹ˆä¸å‘¢ğŸ˜†""", 

                        label="ä½¿ç”¨æç¤ºè¯",
                        interactive=False,
                        show_label=False,
                        lines=12,
                        elem_classes="prompt-guide"
                    )
            with gr.Column(scale=1):
                caption_detail = gr.Radio(
                    choices=["<CAPTION>","<DETAILED_CAPTION>", "<MORE_DETAILED_CAPTION>"],
                    value="<CAPTION>",
                    label="Florence-2 æè¿°è¯¦ç¨‹åº¦",
                    info="é€‰æ‹©å›¾åƒåˆ†æçš„è¯¦ç»†ç¨‹åº¦"
                )
                generate_prompt_btn = gr.Button("ğŸ“ ç”Ÿæˆæç¤ºè¯", variant="primary")
        with gr.Row():
            negative_prompt = gr.Textbox(
                label="åå‘æç¤ºè¯",
                value="worst quality, low quality, normal quality",
            )
        with gr.Row():
            with gr.Column(scale=8):
                seed = gr.Slider(
                    minimum=-1,
                    maximum=10_000,
                    step=1,
                    value=-1,
                    label="ç§å­å€¼ (-1ä¸ºéšæœº)"
                )
            with gr.Column(scale=1):
                reuse_seed = gr.Checkbox(label="é‡ç”¨ä¸Šæ¬¡ç§å­å€¼", value=False)
                
    with gr.Accordion("åŸºæœ¬é€‰é¡¹", open=False):
        with gr.Row():    
            upscale_factor = gr.Slider(
                minimum=1,
                maximum=4,
                value=2,
                step=0.2,
                label="æ”¾å¤§å€æ•°",
            )
            denoise_strength = gr.Slider(
                minimum=0.05,
                maximum=1,
                value=0.15,
                step=0.05,
                label="é™å™ªå¼ºåº¦", 
                info="è®¾ä¸ºæœ€å°å€¼è·å¾—æ›´ä¼ ç»Ÿçš„æ”¾å¤§æ•ˆæœ",
            )
            num_inference_steps = gr.Slider(
                minimum=1,
                maximum=50,
                value=20,
                step=1,
                label="æ¨ç†æ­¥æ•°",
            )
    with gr.Accordion("é«˜çº§é€‰é¡¹", open=False):
        with gr.Row(): 
            controlnet_scale = gr.Slider(
                minimum=0,
                maximum=1.5,
                value=0.6,
                step=0.1,
                label="ControlNetå¼ºåº¦",
            )
            controlnet_decay = gr.Slider(
                minimum=0.5,
                maximum=1,
                value=1.0,
                step=0.025,
                label="ControlNetè¡°å‡",
            )
            condition_scale = gr.Slider(
                minimum=2,
                maximum=20,
                value=6,
                step=1,
                label="æ¡ä»¶ç¼©æ”¾",
            )
        with gr.Row(): 
            tile_width = gr.Slider(
                minimum=64,
                maximum=200,
                value=112,
                step=1,
                label="æ½œç©ºé—´åˆ‡ç‰‡å®½åº¦",
            )
            tile_height = gr.Slider(
                minimum=64,
                maximum=200,
                value=144,
                step=1,
                label="æ½œç©ºé—´åˆ‡ç‰‡é«˜åº¦",
            )
            solver = gr.Radio(
                choices=["DDIM", "DPMSolver"],
                value="DDIM",
                label="æ±‚è§£å™¨",
            )
    with gr.Accordion("ç³»ç»Ÿä¿¡æ¯å’Œæ§åˆ¶å°", open=True):            
        with gr.Row():       
            # Status Info (for cpu/gpu monitor)
            resource_monitor = gr.Textbox(
                label="ç³»ç»Ÿç›‘è§†å™¨",
                lines=8,
                interactive=False,
                # value=get_welcome_message()
            )  
            console_out = gr.Textbox(
                label="æ§åˆ¶å°",
                lines=8,
                interactive=False,
                show_copy_button=True,
                autoscroll=True,    # Enables automatic scrolling to newest messages
                elem_classes="console-scroll"  # Add custom class for styling
            )
 
    with gr.Accordion("å›¾åº“", open=False):     
        with gr.Row():
            gallery = gr.Gallery(
                label="æœ€è¿‘å¢å¼º",
                show_label=True,
                elem_id="gallery",
                columns=5,
                rows=6,
                height="80vh",  # Use viewport height instead of fixed pixels
                object_fit="contain",
                allow_preview=True,
                show_share_button=False,
                show_download_button=True,
                preview=True,
            )
            
    # Event handlers
    
    generate_prompt_btn.click(
        fn=generate_prompt,
        inputs=[input_image, caption_detail],
        outputs=[prompt]
    )
    
    run_button.click(
        fn=process_and_update,
        inputs=[
            input_image,
            prompt,
            negative_prompt,
            seed,
            reuse_seed,
            upscale_factor,
            controlnet_scale,
            controlnet_decay,
            condition_scale,
            tile_width,
            tile_height,
            denoise_strength,
            num_inference_steps,
            solver,
            auto_save,
        ],
        outputs=[output_slider, gallery]
    )
    
    batch_button.click(
        fn=batch_process_images,
        inputs=[
            input_files,
            prompt,
            negative_prompt,
            seed,
            reuse_seed,
            upscale_factor,
            controlnet_scale,
            controlnet_decay,
            condition_scale,
            tile_width,
            tile_height,
            denoise_strength,
            num_inference_steps,
            solver,
        ],
        outputs=[batch_status, gallery, output_slider]
    )
    
    save_result.click(
        fn=save_output,
        inputs=None,
        outputs=[gallery]
    )
    
    open_folder_button.click(
        fn=open_output_folder,
        inputs=None,
        outputs=gr.Text(visible=False) 
    )
    
    def update_console():
        return message_manager.get_messages()
    
    # Initialize the timer and set up its tick event
    demo.load(
        fn=lambda: (SystemMonitor.get_system_info(), update_console()),
        outputs=[resource_monitor, console_out],
        every=1  # Updates every 1 second
    )
    
demo.launch(share=False)
